看到的问题汇总；
-------------------------------------
spark streaming读取kafka消息的并发问题。

现象描述：某些 Spark 分区已经处理完数据了，另一部分分区还在处理数据，从而导致这个批次的作业总消耗时间变长；甚至导致 Spark 作业无法及时消费 Kafka 中的数据。（统一基于spark direct模式）

问题解决的想法：1：针对spark的getPartition做源码的改造，使得kafka每个分区有多个spark分区去消费。但是问题在于这种方式可能会造成kafka同一分区的数据消费的无序性，违背了设计的初衷。
            2：在数据处理之前对数据进行repartition和coalease，前提是要比没有重新分区直接处理数据的时间要短。否则就没有什么意义了。
            3：上述两种方式都是针对kafka端数据倾斜问题的方针。针对是由于kafka吞吐量带来数据量大的问题，则需要考虑增加kafka的分区数量，和提高spark计算资源等。慎重主要不要多线程来读取同一个分区的数据。

相关地址链接：https://mp.weixin.qq.com/s/JgLo9OdpwhrUm6jnU2uPmg

